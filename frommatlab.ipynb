{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frommatlab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeibelT/colab/blob/master/frommatlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBU__i7j2pU",
        "colab_type": "text"
      },
      "source": [
        "# **Training a network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHdXYoRQJYLb",
        "colab_type": "text"
      },
      "source": [
        " **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxy9R5p_JG7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d929c692-a037-4f58-dd0f-db1cf7f25599"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D,Dropout\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Model,layers\n",
        "from keras.optimizers import Adam,SGD,Adadelta\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDqMsN2kKqH",
        "colab_type": "text"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ka3d6tYZTZQ",
        "colab_type": "text"
      },
      "source": [
        "To be able to import Data in google Colaboratory, we have to connect to My_Drive first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo57FH4hkJ-C",
        "colab_type": "code",
        "outputId": "04828040-936e-459c-dee8-c6d253facadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount(\"My_Drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at My_Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkwEIv_3pIub",
        "colab_type": "text"
      },
      "source": [
        "If not working try \"Reset all Runtime\" in Runtime-menu or try following code(remove hashtags first):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OteNoZsZJdd7",
        "colab_type": "text"
      },
      "source": [
        "# Datagen for training, validation and testing\n",
        "\n",
        "target_size equal to Model input_size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPb2u_oRRa6X",
        "colab_type": "code",
        "outputId": "a7daa5ba-99d4-48cf-ca79-0d7fadeb7399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "     'My_Drive/My Drive/TransferedMatlabcode/data_rearranged/training',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "     'My_Drive/My Drive/TransferedMatlabcode/data_rearranged/validation',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3496 images belonging to 8 classes.\n",
            "Found 760 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGDj51axaWlA",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRI1J75ZN-sT",
        "colab_type": "text"
      },
      "source": [
        "**Load Resnet without top layers and create own model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WzLt4tYLQxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=ResNet50(weights='imagenet',include_top=False) #imports the Restnet50 model without last layers.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(128,activation='relu')(x) #add some dense layers, Dropoutlayers(less overfitting)\n",
        "x=Dropout(0.3)(x)\n",
        "x=Dense(128,activation='relu')(x) #dense layer 2\n",
        "x=Dropout(0.3)(x)\n",
        "x=Dense(64,activation='sigmoid')(x) #dense layer 3\n",
        "preds=Dense(8,activation='softmax')(x) #final layer with softmax \n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "\n",
        "\n",
        "#show Layers from new model\n",
        "#for i,layer in enumerate(model.layers):\n",
        "#  print(i,layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx70vTQdkSa8",
        "colab_type": "text"
      },
      "source": [
        "# Train Model\n",
        "\n",
        "with different Optimizer\n",
        "select optimizer, make if-Function True, others False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoFYlhOUcVyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "33a72ae7-d5bb-4d17-a907-f46f0491559b"
      },
      "source": [
        "if True:\n",
        "  \"\"\"Adam Optimizer\"\"\"\n",
        "  ADAM=keras.optimizers.Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=ADAM,metrics=['accuracy'])\n",
        "  # Adam optimizer\n",
        "  # loss function will be categorical cross entropy, since dataset has more categories\n",
        "  # evaluation metric will be accuracy\n",
        "\n",
        "if False:\n",
        "  \"\"\"SGD Optimizer\"\"\"\n",
        "  sgd=keras.optimizers.SGD(lr=0.001)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "if False:\n",
        "  \"\"\"Adadelta optimizer\"\"\"\n",
        "  adadelt= keras.optimizers.Adadelta(lr=0.1)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=adadelt,metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\"\"\"train model,(later use history for confusion matrix)\"\"\"\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "step_size_valid=validation_generator.n//train_generator.batch_size\n",
        "\n",
        "history=model.fit_generator(generator=train_generator,\n",
        "                    validation_data=validation_generator, validation_steps=step_size_valid, validation_freq=1,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=15\n",
        "                   )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/15\n",
            " 31/109 [=======>......................] - ETA: 15:53 - loss: 1.6015 - acc: 0.4929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 37 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 91/109 [========================>.....] - ETA: 3:38 - loss: 1.1334 - acc: 0.7170"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 32 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 95/109 [=========================>....] - ETA: 2:54 - loss: 1.1173 - acc: 0.7240"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 8 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "102/109 [===========================>..] - ETA: 1:30 - loss: 1.0956 - acc: 0.7316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 20 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "109/109 [==============================] - 1587s 15s/step - loss: 1.0738 - acc: 0.7382 - val_loss: 0.9931 - val_acc: 0.7269\n",
            "Epoch 2/15\n",
            "  1/109 [..............................] - ETA: 2:34 - loss: 1.1982 - acc: 0.5000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHDORwGZMAw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5OQ9PzV1bk2",
        "colab_type": "text"
      },
      "source": [
        "# Save Model\n",
        "if necessary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Jf9vzroyii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#architecture and weights to HDF5\n",
        "#model.save('My_Drive/My Drive/TransferedMatlabcode/model_sgd_resnet50_50epochs.h5')\n",
        "\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wlldem1gaE",
        "colab_type": "text"
      },
      "source": [
        "# Create Datagen for testing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKTxyKUQCIkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "bc1c0e17-1eeb-4e7e-aa3b-f65f7e434a03"
      },
      "source": [
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input)\n",
        "\n",
        "\n",
        "\n",
        "test_generator= test_datagen.flow_from_directory(\n",
        "     'My_Drive/My Drive/TransferedMatlabcode/data_rearranged/test',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4a4d9f948a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     shuffle=False)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'My_Drive/My Drive/TransferedMatlabcode/data_rearranged/test'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiPa7zSTAFF5",
        "colab_type": "text"
      },
      "source": [
        "# Confusion Matrix \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nwG4A68mDHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(history.history.keys())\n",
        "\n",
        "num_of_test_samples=760\n",
        "batch_size=32\n",
        "\n",
        "pred = model.predict_generator(test_generator)\n",
        "Pred = np.argmax(pred, axis=1) #scale 0-1\n",
        "print('simple Confusion Matrix:')\n",
        "print(confusion_matrix(test_generator.classes, Pred))\n",
        "print('Classification Report:')\n",
        "target_names = [\"Tumor\", \"Stroma\", \"Complex\", \"Lympho\", \"Debris\" ,\"Mucosa\", \"Adipose\", \"Empty\"]\n",
        "\n",
        "#classification report (?)\n",
        "print(classification_report(test_generator.classes, Pred, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiiBHH2HAK-o",
        "colab_type": "text"
      },
      "source": [
        "# Plot Accuracy & Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Qn4RT0ng97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
        "\n",
        "ax1.plot(history.history['acc'],label=\"training\")\n",
        "ax1.plot(history.history['val_acc'],label=\"validation\")\n",
        "ax1.axhline(max(history.history['val_acc']),color=\"grey\",label=\"max val accuracy\")\n",
        "ax1.set_title(\"Accuracy \")\n",
        "ax1.set_ylabel(\"accuracy\")\n",
        "\n",
        "ax1.legend()\n",
        "ax2.plot(history.history['loss'],label=\"training\")\n",
        "ax2.plot(history.history['val_loss'],label=\"validation\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylabel(\"loss\")\n",
        "ax2.legend()\n",
        "\n",
        "\n",
        "\"\"\"to save fig as pdf:\"\"\"\n",
        "fname=\"My_Drive/My Drive/TransferedMatlabcode/plot_training_resnet_Adadelta\"\n",
        "#plt.savefig(fname, format=\"pdf\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}